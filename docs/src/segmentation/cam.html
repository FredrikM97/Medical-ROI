<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>src.segmentation.cam API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.segmentation.cam</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from src.utils import utils,plot, preprocess
from torchcam import cams
import torch
from torch import Tensor
import numpy as np
from typing import Tuple, Union, List
import enum
from src.utils.plots.parula import parula_map
import torchvision
import matplotlib.pyplot as plt

class SaliencyMap:
    def __init__(self, model, target_layer=None,input_shape=(1,79,95,79)):
        self.model = model
        self.target_layer = None
        self.input_shape = input_shape
        
    def __call__(self, class_idx,class_scores): 
        raise NotImplemented
        # Return an activation map which is not normalized
        #assert image.shape == input_shape
        #for param in self.model.parameters():
        #    param.requires_grad = False
        
        #class_idx = class_scores.argmax()
        #output_max = class_scores[0, class_idx]

        # Do backpropagation to get the derivative of the output based on the image
        #output_max.backward()

        #preds = model(image)
        #score, indices = torch.max(preds, 1)
        #score, indices = torch.max(class_scores, 1)
        #score.retain_grad()
        #score.backward()

        # Get max along channel axis
        #activation_map, _ = torch.max(torch.abs(score.grad[0]), dim=0)
        #print(activation_map)
        #activations, _ = torch.max(score.grad.data.abs(), dim=1) 
        #print(self.model.grad.data.abs())
        #return activation_map

class CAMS(enum.Enum):
    CAM = cams.CAM
    ScoreCAM = cams.ScoreCAM
    SSCAM = cams.SSCAM
    ISSCAM = cams.ISCAM
    GradCAM = cams.GradCAM
    GradCAMpp = cams.GradCAMpp
    SmoothGradCAMpp = cams.SmoothGradCAMpp
    #Saliency = SaliencyMap
    
class CAM(plot.Plot):
    &#34;&#34;&#34;
    Example usage:
    trainer, dataset, model = load_trainer(&#39;resnet50&#39;)
    tmp_image = nib.load(&#39;../data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii&#39;).get_fdata()
    tmp = cam.CAM(CAMS.GradCAM.value, model, tmp_image)
    
    tmp.plot(tmp.class_scores, [0,1,2], class_label=&#34;AD&#34;)
    &#34;&#34;&#34;
    def __init__(self, cam:str, model, image:np.ndarray, input_shape:Tuple[int,int,int,int]=(1,79,95,79), target_layer:str=None) -&gt; None:
        super().__init__()
        self.cam = cam
        self.model = model
        self.image = image
        self.extractor = cam(model, input_shape=input_shape, target_layer=target_layer)
        self.input_shape = input_shape
        self.class_scores, self.class_idx = self.evaluate()

    def _cam_scores(self) -&gt; Tensor:
        &#34;&#34;&#34; Sign it over so we dont have to call self each time. Note: Is this a copy? 
            
            Return a score vector with the propbability of each class
        &#34;&#34;&#34;
        
        # Apply preprocessing
        image = self.preprocess(self.image)
        image = preprocess.batchisize_to_5D(image)
        image_tensor = torch.from_numpy(image).float()
        
        image_tensor.to(self.model.device)
        # Check that image have the correct shape
        assert tuple(image_tensor.shape) == (1, *self.input_shape), f&#34;Got image shape: {image_tensor.shape} expected: {(1, *self.input_shape)}&#34;
        #assert self.model.device == image.device, f&#34;Model and image are not on same device: Model: {self.model.device} Image: {image.device}&#34;
        
        #image_tensor.requires_grad = True
        
        # Enable grad and configure model
        #for param in self.model.parameters():
        #    param.requires_grad = False
        
        self.model.eval()
        class_scores = self.model(image_tensor)
        return class_scores
    
    def _class_idx(self, class_score:Tensor):
        &#34;&#34;&#34;Convert score vector with probabilities into the maximum score value&#34;&#34;&#34;
        return class_score.squeeze(0).argmax().item()
    
    def evaluate(self) -&gt; Tuple[Tensor, int]:
        &#34;&#34;&#34;Calculate the class scores and the highest probability of the target class
        
        Return:
            * Tuple containing all the probabilities and the best probability class
        &#34;&#34;&#34;
        class_scores = self._cam_scores() 
        return class_scores, self._class_idx(class_scores)
    
    def activation_map(self, class_idx:int=None, class_scores:Tensor=None) -&gt; np.ndarray:
        &#34;&#34;&#34; Retrieve the map based on the score from the model
            Return a Tensor with activations from image
        &#34;&#34;&#34;
        
        return utils.tensor2numpy(self.extractor(class_idx, class_scores))
       
    def grid_class(self, class_scores:Tensor, class_idx:Union[List[int],int], max_num_slices:int=16) -&gt; Tuple[Tensor, Tensor]:
        &#34;&#34;&#34;Creates a grid based on a class_idx.&#34;&#34;&#34;
        if isinstance(class_idx, list) and len(class_idx) == 1:
            class_idx = class_idx[0]

        
        if isinstance(class_idx, list):
            grid_img = torch.hstack([
                self.grid(self.image, max_num_slices=max_num_slices)
                for _ in class_idx
            ])
            
            print(class_scores, class_idx)
            grid_mask = torch.hstack([
                self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
                for class_idx in class_idx
            ])
        
            
        elif isinstance(class_idx, int):
            grid_mask = self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
            grid_img = self.grid(self.image, max_num_slices=max_num_slices)
            
        else:
            raise ValueError(f&#34;Expected class_idx of type list or int, Got: {type(class_idx)}&#34;)
            
        return grid_img, grid_mask
        
    def plot(self, class_scores:Tensor, class_idx:Union[List[int],int],cmap=parula_map, alpha=0.3, class_label:str=None, predicted_override=None, max_num_slices:int=16):
        &#34;&#34;&#34;Create a plot from the given class activation map and input image. CAM is calculated from the models weights and the probability distribution of each class.&#34;&#34;&#34;
        class_idx = class_idx if isinstance(class_idx, list) else [class_idx]
        
        def default_settings(axis, predicted_label):
            classes = {
                0:&#39;CN&#39;,
                1:&#39;MCI&#39;,
                2:&#39;AD&#39;
            }
            title_list = [out for out, con in [
                (f&#39;{type(self.model.model).__name__}&#39;,True),
                (f&#39;{type(self.extractor).__name__}&#39;,True),
                (f&#39;Patient: {class_label}&#39;,class_label),
                (f&#39;Predicted: {classes[predicted_label]}&#39;,predicted_label),
                (f&#39;Overrided&#39;,predicted_override)] if con != None
            ]
            axis.set_title(&#39;, &#39;.join(title_list))
            
        fig, axes = plt.subplots(ncols=len(class_idx),nrows=1,figsize=(len(class_idx)*8,8))
        fig.subplots_adjust(hspace=0)
        
        if len(class_idx) == 1:
            image, mask = self.grid_class(class_scores, class_idx[0])
            axes.imshow(image,cmap=&#39;Greys_r&#39;)
            im = axes.imshow(mask,cmap=cmap, alpha=alpha) 
            default_settings(axes,class_idx[0])
        else:
            for i, idx in enumerate(class_idx):
                image, mask = self.grid_class(class_scores, idx)
                axes[i].imshow(image,cmap=&#39;Greys_r&#39;)
                im = axes[i].imshow(mask,cmap=cmap, alpha=alpha) 
                default_settings(axes[i], idx)
        
        # Remove axis data to show colorbar more clean
        for ax in axes.flat:
            ax.set_axis_off()
            ax.set_xticklabels([])
            ax.set_yticklabels([])
    
        plt.subplots_adjust(wspace=0.01, hspace=0)
        cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=1)

        
        return fig
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.segmentation.cam.CAM"><code class="flex name class">
<span>class <span class="ident">CAM</span></span>
<span>(</span><span>cam: str, model, image: numpy.ndarray, input_shape: Tuple[int, int, int, int] = (1, 79, 95, 79), target_layer: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Example usage:
trainer, dataset, model = load_trainer('resnet50')
tmp_image = nib.load('../data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii').get_fdata()
tmp = cam.CAM(CAMS.GradCAM.value, model, tmp_image)</p>
<p>tmp.plot(tmp.class_scores, [0,1,2], class_label="AD")</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CAM(plot.Plot):
    &#34;&#34;&#34;
    Example usage:
    trainer, dataset, model = load_trainer(&#39;resnet50&#39;)
    tmp_image = nib.load(&#39;../data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii&#39;).get_fdata()
    tmp = cam.CAM(CAMS.GradCAM.value, model, tmp_image)
    
    tmp.plot(tmp.class_scores, [0,1,2], class_label=&#34;AD&#34;)
    &#34;&#34;&#34;
    def __init__(self, cam:str, model, image:np.ndarray, input_shape:Tuple[int,int,int,int]=(1,79,95,79), target_layer:str=None) -&gt; None:
        super().__init__()
        self.cam = cam
        self.model = model
        self.image = image
        self.extractor = cam(model, input_shape=input_shape, target_layer=target_layer)
        self.input_shape = input_shape
        self.class_scores, self.class_idx = self.evaluate()

    def _cam_scores(self) -&gt; Tensor:
        &#34;&#34;&#34; Sign it over so we dont have to call self each time. Note: Is this a copy? 
            
            Return a score vector with the propbability of each class
        &#34;&#34;&#34;
        
        # Apply preprocessing
        image = self.preprocess(self.image)
        image = preprocess.batchisize_to_5D(image)
        image_tensor = torch.from_numpy(image).float()
        
        image_tensor.to(self.model.device)
        # Check that image have the correct shape
        assert tuple(image_tensor.shape) == (1, *self.input_shape), f&#34;Got image shape: {image_tensor.shape} expected: {(1, *self.input_shape)}&#34;
        #assert self.model.device == image.device, f&#34;Model and image are not on same device: Model: {self.model.device} Image: {image.device}&#34;
        
        #image_tensor.requires_grad = True
        
        # Enable grad and configure model
        #for param in self.model.parameters():
        #    param.requires_grad = False
        
        self.model.eval()
        class_scores = self.model(image_tensor)
        return class_scores
    
    def _class_idx(self, class_score:Tensor):
        &#34;&#34;&#34;Convert score vector with probabilities into the maximum score value&#34;&#34;&#34;
        return class_score.squeeze(0).argmax().item()
    
    def evaluate(self) -&gt; Tuple[Tensor, int]:
        &#34;&#34;&#34;Calculate the class scores and the highest probability of the target class
        
        Return:
            * Tuple containing all the probabilities and the best probability class
        &#34;&#34;&#34;
        class_scores = self._cam_scores() 
        return class_scores, self._class_idx(class_scores)
    
    def activation_map(self, class_idx:int=None, class_scores:Tensor=None) -&gt; np.ndarray:
        &#34;&#34;&#34; Retrieve the map based on the score from the model
            Return a Tensor with activations from image
        &#34;&#34;&#34;
        
        return utils.tensor2numpy(self.extractor(class_idx, class_scores))
       
    def grid_class(self, class_scores:Tensor, class_idx:Union[List[int],int], max_num_slices:int=16) -&gt; Tuple[Tensor, Tensor]:
        &#34;&#34;&#34;Creates a grid based on a class_idx.&#34;&#34;&#34;
        if isinstance(class_idx, list) and len(class_idx) == 1:
            class_idx = class_idx[0]

        
        if isinstance(class_idx, list):
            grid_img = torch.hstack([
                self.grid(self.image, max_num_slices=max_num_slices)
                for _ in class_idx
            ])
            
            print(class_scores, class_idx)
            grid_mask = torch.hstack([
                self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
                for class_idx in class_idx
            ])
        
            
        elif isinstance(class_idx, int):
            grid_mask = self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
            grid_img = self.grid(self.image, max_num_slices=max_num_slices)
            
        else:
            raise ValueError(f&#34;Expected class_idx of type list or int, Got: {type(class_idx)}&#34;)
            
        return grid_img, grid_mask
        
    def plot(self, class_scores:Tensor, class_idx:Union[List[int],int],cmap=parula_map, alpha=0.3, class_label:str=None, predicted_override=None, max_num_slices:int=16):
        &#34;&#34;&#34;Create a plot from the given class activation map and input image. CAM is calculated from the models weights and the probability distribution of each class.&#34;&#34;&#34;
        class_idx = class_idx if isinstance(class_idx, list) else [class_idx]
        
        def default_settings(axis, predicted_label):
            classes = {
                0:&#39;CN&#39;,
                1:&#39;MCI&#39;,
                2:&#39;AD&#39;
            }
            title_list = [out for out, con in [
                (f&#39;{type(self.model.model).__name__}&#39;,True),
                (f&#39;{type(self.extractor).__name__}&#39;,True),
                (f&#39;Patient: {class_label}&#39;,class_label),
                (f&#39;Predicted: {classes[predicted_label]}&#39;,predicted_label),
                (f&#39;Overrided&#39;,predicted_override)] if con != None
            ]
            axis.set_title(&#39;, &#39;.join(title_list))
            
        fig, axes = plt.subplots(ncols=len(class_idx),nrows=1,figsize=(len(class_idx)*8,8))
        fig.subplots_adjust(hspace=0)
        
        if len(class_idx) == 1:
            image, mask = self.grid_class(class_scores, class_idx[0])
            axes.imshow(image,cmap=&#39;Greys_r&#39;)
            im = axes.imshow(mask,cmap=cmap, alpha=alpha) 
            default_settings(axes,class_idx[0])
        else:
            for i, idx in enumerate(class_idx):
                image, mask = self.grid_class(class_scores, idx)
                axes[i].imshow(image,cmap=&#39;Greys_r&#39;)
                im = axes[i].imshow(mask,cmap=cmap, alpha=alpha) 
                default_settings(axes[i], idx)
        
        # Remove axis data to show colorbar more clean
        for ax in axes.flat:
            ax.set_axis_off()
            ax.set_xticklabels([])
            ax.set_yticklabels([])
    
        plt.subplots_adjust(wspace=0.01, hspace=0)
        cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=1)

        
        return fig</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="src.utils.plot.Plot" href="../utils/plot.html#src.utils.plot.Plot">Plot</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="src.segmentation.cam.CAM.activation_map"><code class="name flex">
<span>def <span class="ident">activation_map</span></span>(<span>self, class_idx: int = None, class_scores: torch.Tensor = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the map based on the score from the model
Return a Tensor with activations from image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def activation_map(self, class_idx:int=None, class_scores:Tensor=None) -&gt; np.ndarray:
    &#34;&#34;&#34; Retrieve the map based on the score from the model
        Return a Tensor with activations from image
    &#34;&#34;&#34;
    
    return utils.tensor2numpy(self.extractor(class_idx, class_scores))</code></pre>
</details>
</dd>
<dt id="src.segmentation.cam.CAM.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self) ‑> Tuple[torch.Tensor, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the class scores and the highest probability of the target class</p>
<h2 id="return">Return</h2>
<ul>
<li>Tuple containing all the probabilities and the best probability class</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self) -&gt; Tuple[Tensor, int]:
    &#34;&#34;&#34;Calculate the class scores and the highest probability of the target class
    
    Return:
        * Tuple containing all the probabilities and the best probability class
    &#34;&#34;&#34;
    class_scores = self._cam_scores() 
    return class_scores, self._class_idx(class_scores)</code></pre>
</details>
</dd>
<dt id="src.segmentation.cam.CAM.grid_class"><code class="name flex">
<span>def <span class="ident">grid_class</span></span>(<span>self, class_scores: torch.Tensor, class_idx: Union[List[int], int], max_num_slices: int = 16) ‑> Tuple[torch.Tensor, torch.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a grid based on a class_idx.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def grid_class(self, class_scores:Tensor, class_idx:Union[List[int],int], max_num_slices:int=16) -&gt; Tuple[Tensor, Tensor]:
    &#34;&#34;&#34;Creates a grid based on a class_idx.&#34;&#34;&#34;
    if isinstance(class_idx, list) and len(class_idx) == 1:
        class_idx = class_idx[0]

    
    if isinstance(class_idx, list):
        grid_img = torch.hstack([
            self.grid(self.image, max_num_slices=max_num_slices)
            for _ in class_idx
        ])
        
        print(class_scores, class_idx)
        grid_mask = torch.hstack([
            self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
            for class_idx in class_idx
        ])
    
        
    elif isinstance(class_idx, int):
        grid_mask = self.grid(self.activation_map(class_idx, class_scores), max_num_slices=max_num_slices)
        grid_img = self.grid(self.image, max_num_slices=max_num_slices)
        
    else:
        raise ValueError(f&#34;Expected class_idx of type list or int, Got: {type(class_idx)}&#34;)
        
    return grid_img, grid_mask</code></pre>
</details>
</dd>
<dt id="src.segmentation.cam.CAM.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, class_scores: torch.Tensor, class_idx: Union[List[int], int], cmap=&lt;matplotlib.colors.LinearSegmentedColormap object&gt;, alpha=0.3, class_label: str = None, predicted_override=None, max_num_slices: int = 16)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a plot from the given class activation map and input image. CAM is calculated from the models weights and the probability distribution of each class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, class_scores:Tensor, class_idx:Union[List[int],int],cmap=parula_map, alpha=0.3, class_label:str=None, predicted_override=None, max_num_slices:int=16):
    &#34;&#34;&#34;Create a plot from the given class activation map and input image. CAM is calculated from the models weights and the probability distribution of each class.&#34;&#34;&#34;
    class_idx = class_idx if isinstance(class_idx, list) else [class_idx]
    
    def default_settings(axis, predicted_label):
        classes = {
            0:&#39;CN&#39;,
            1:&#39;MCI&#39;,
            2:&#39;AD&#39;
        }
        title_list = [out for out, con in [
            (f&#39;{type(self.model.model).__name__}&#39;,True),
            (f&#39;{type(self.extractor).__name__}&#39;,True),
            (f&#39;Patient: {class_label}&#39;,class_label),
            (f&#39;Predicted: {classes[predicted_label]}&#39;,predicted_label),
            (f&#39;Overrided&#39;,predicted_override)] if con != None
        ]
        axis.set_title(&#39;, &#39;.join(title_list))
        
    fig, axes = plt.subplots(ncols=len(class_idx),nrows=1,figsize=(len(class_idx)*8,8))
    fig.subplots_adjust(hspace=0)
    
    if len(class_idx) == 1:
        image, mask = self.grid_class(class_scores, class_idx[0])
        axes.imshow(image,cmap=&#39;Greys_r&#39;)
        im = axes.imshow(mask,cmap=cmap, alpha=alpha) 
        default_settings(axes,class_idx[0])
    else:
        for i, idx in enumerate(class_idx):
            image, mask = self.grid_class(class_scores, idx)
            axes[i].imshow(image,cmap=&#39;Greys_r&#39;)
            im = axes[i].imshow(mask,cmap=cmap, alpha=alpha) 
            default_settings(axes[i], idx)
    
    # Remove axis data to show colorbar more clean
    for ax in axes.flat:
        ax.set_axis_off()
        ax.set_xticklabels([])
        ax.set_yticklabels([])

    plt.subplots_adjust(wspace=0.01, hspace=0)
    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=1)

    
    return fig</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="src.utils.plot.Plot" href="../utils/plot.html#src.utils.plot.Plot">Plot</a></b></code>:
<ul class="hlist">
<li><code><a title="src.utils.plot.Plot.grid" href="../utils/plot.html#src.utils.plot.Plot.grid">grid</a></code></li>
<li><code><a title="src.utils.plot.Plot.preprocess" href="../utils/plot.html#src.utils.plot.Plot.preprocess">preprocess</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="src.segmentation.cam.CAMS"><code class="flex name class">
<span>class <span class="ident">CAMS</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CAMS(enum.Enum):
    CAM = cams.CAM
    ScoreCAM = cams.ScoreCAM
    SSCAM = cams.SSCAM
    ISSCAM = cams.ISCAM
    GradCAM = cams.GradCAM
    GradCAMpp = cams.GradCAMpp
    SmoothGradCAMpp = cams.SmoothGradCAMpp
    #Saliency = SaliencyMap</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.segmentation.cam.CAMS.CAM"><code class="name">var <span class="ident">CAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.GradCAM"><code class="name">var <span class="ident">GradCAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.GradCAMpp"><code class="name">var <span class="ident">GradCAMpp</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.ISSCAM"><code class="name">var <span class="ident">ISSCAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.SSCAM"><code class="name">var <span class="ident">SSCAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.ScoreCAM"><code class="name">var <span class="ident">ScoreCAM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.segmentation.cam.CAMS.SmoothGradCAMpp"><code class="name">var <span class="ident">SmoothGradCAMpp</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="src.segmentation.cam.SaliencyMap"><code class="flex name class">
<span>class <span class="ident">SaliencyMap</span></span>
<span>(</span><span>model, target_layer=None, input_shape=(1, 79, 95, 79))</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SaliencyMap:
    def __init__(self, model, target_layer=None,input_shape=(1,79,95,79)):
        self.model = model
        self.target_layer = None
        self.input_shape = input_shape
        
    def __call__(self, class_idx,class_scores): 
        raise NotImplemented
        # Return an activation map which is not normalized
        #assert image.shape == input_shape
        #for param in self.model.parameters():
        #    param.requires_grad = False
        
        #class_idx = class_scores.argmax()
        #output_max = class_scores[0, class_idx]

        # Do backpropagation to get the derivative of the output based on the image
        #output_max.backward()

        #preds = model(image)
        #score, indices = torch.max(preds, 1)
        #score, indices = torch.max(class_scores, 1)
        #score.retain_grad()
        #score.backward()

        # Get max along channel axis
        #activation_map, _ = torch.max(torch.abs(score.grad[0]), dim=0)
        #print(activation_map)
        #activations, _ = torch.max(score.grad.data.abs(), dim=1) 
        #print(self.model.grad.data.abs())
        #return activation_map</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.segmentation" href="index.html">src.segmentation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.segmentation.cam.CAM" href="#src.segmentation.cam.CAM">CAM</a></code></h4>
<ul class="">
<li><code><a title="src.segmentation.cam.CAM.activation_map" href="#src.segmentation.cam.CAM.activation_map">activation_map</a></code></li>
<li><code><a title="src.segmentation.cam.CAM.evaluate" href="#src.segmentation.cam.CAM.evaluate">evaluate</a></code></li>
<li><code><a title="src.segmentation.cam.CAM.grid_class" href="#src.segmentation.cam.CAM.grid_class">grid_class</a></code></li>
<li><code><a title="src.segmentation.cam.CAM.plot" href="#src.segmentation.cam.CAM.plot">plot</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.segmentation.cam.CAMS" href="#src.segmentation.cam.CAMS">CAMS</a></code></h4>
<ul class="two-column">
<li><code><a title="src.segmentation.cam.CAMS.CAM" href="#src.segmentation.cam.CAMS.CAM">CAM</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.GradCAM" href="#src.segmentation.cam.CAMS.GradCAM">GradCAM</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.GradCAMpp" href="#src.segmentation.cam.CAMS.GradCAMpp">GradCAMpp</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.ISSCAM" href="#src.segmentation.cam.CAMS.ISSCAM">ISSCAM</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.SSCAM" href="#src.segmentation.cam.CAMS.SSCAM">SSCAM</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.ScoreCAM" href="#src.segmentation.cam.CAMS.ScoreCAM">ScoreCAM</a></code></li>
<li><code><a title="src.segmentation.cam.CAMS.SmoothGradCAMpp" href="#src.segmentation.cam.CAMS.SmoothGradCAMpp">SmoothGradCAMpp</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.segmentation.cam.SaliencyMap" href="#src.segmentation.cam.SaliencyMap">SaliencyMap</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>