{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "productive-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heated-exclusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neural_network.configs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2f2a49d2307a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note: Assume the following: (batch_size, channel, height, width, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stud1/f/fremar16/Master_thesis/Development/neural_network/ml_lightning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivationMapCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetricCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCAMCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLitProgressBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neural_network.configs'"
     ]
    }
   ],
   "source": [
    "from neural_network.trainer import Agent\n",
    "# Note: Assume the following: (batch_size, channel, height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent('resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(agent.dataset.train_dataloader()).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "input_tensor = iter(agent.dataset.val_dataloader()).next()[0][0].unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = agent.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchcam.cams import SSCAM\n",
    "import torch\n",
    "\n",
    "def get_CAM(agent,input_tensor):\n",
    "    model = agent.model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    cam = SSCAM(\n",
    "        model.model, \n",
    "        'layer4',\n",
    "        batch_size = 1,\n",
    "        num_samples = 1,\n",
    "        std = 2.0,\n",
    "        input_shape = (1, 79, 224, 224),\n",
    "    )\n",
    "    with torch.no_grad(): \n",
    "        scores = model.model(input_tensor)\n",
    "        activation_map = cam(scores.squeeze(0).argmax().item(), scores).cpu()\n",
    "    return activation_map,scores\n",
    "get_CAM(agent, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgmap = cm.get_cmap('gray')\n",
    "img = imgmap(input_tensor.cpu().squeeze(0).squeeze(0))[:,:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data):\n",
    "    f,axes= plt.subplots(7,math.ceil(len(data[0][0])/7), figsize=(14,12.5),subplot_kw={'xticks': [], 'yticks': []})\n",
    "    f.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "    ax = axes.flat\n",
    "    for i in range(len(data[0][0])):\n",
    "        ax[i].imshow(data[:,:,i],vmin=0,vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = cm.get_cmap('jet')\n",
    "imgmap = cm.get_cmap('gray')\n",
    "alpha=0.7\n",
    "\n",
    "def show_slices(data):\n",
    "    f,axes= plt.subplots(7,math.ceil(len(data[0][0])/7), figsize=(14,12.5),subplot_kw={'xticks': [], 'yticks': []})\n",
    "    f.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "    ax = axes.flat\n",
    "    for i in range(len(data[0][0])):\n",
    "        ax[i].imshow(data[:,:,i],vmin=0,vmax=255)\n",
    "\n",
    "#for mask,img in zip(heatmap, input_tensor.cpu().squeeze(0).squeeze(0)):\n",
    "\"\"\"\n",
    "fig = plt.figure()\n",
    "overlay = (255 * cmap(np.asarray(mask) ** 2)[:, :, 1:]).astype(np.uint8)\n",
    "# Overlay the image with the mask\n",
    "\n",
    "img = imgmap(img)[:,:,1:]# = img.unsqueeze(0)\n",
    "#img = img.numpy().transpose((1,2,0))\n",
    "#print(img.shape, mask.shape, overlay.shape, np.asarray(img).shape)\n",
    "overlayed_img = (alpha * np.asarray(img) + (1 - alpha) * overlay).astype(np.uint8)\n",
    "#print(overlayed_img.shape)\n",
    "plt.imshow(mask)\n",
    "\"\"\"\n",
    "heatmap = resize(activation_map, (79,95,79))\n",
    "heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "#overlay = np.uint8(255 * heatmap)\n",
    "jet_colors = cmap(np.arange(256))[:, :3]\n",
    "overlay = jet_colors[heatmap]\n",
    "\n",
    "#overlay = (255*cmap(np.asarray(heatmap))[:, :, :,1:]).astype(np.uint8)\n",
    "img = imgmap(input_tensor.cpu().squeeze(0).squeeze(0))[:,:,:,1:]\n",
    "\n",
    "#print(overlay.max(), img.max(),((1-alpha) * overlay).min())\n",
    "print(img.shape,overlay.shape)\n",
    "overlayed_img = (alpha * np.asarray(img) + (1 - alpha) * overlay)\n",
    "#print(alpha * np.asarray(img))\n",
    "show_slices(overlayed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-cartridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
