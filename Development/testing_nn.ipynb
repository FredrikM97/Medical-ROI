{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "global-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "renewable-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "random-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from neural_network.trainer import Agent\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raising-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup configurations...\n",
      "Dataset sizes - Training: 421 Validation: 47 Test: 0\n",
      "Loading architecture from logs/tb_logs/lightning/resnet50/version_2/checkpoints/epoch=34-step=2424.ckpt (checkpoint)..\n",
      "Model [LightningModel] was created\n",
      "logs/tb_logs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "agent = Agent('resnet50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "figured-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 46.2 M\n",
      "---------------------------------\n",
      "46.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "46.2 M    Total params\n",
      "184.645   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 [71/71] {'loss': '0.482'}}\n",
      "Epoch 2 [71/71] {'loss': '0.315'}\n",
      "Epoch 3 [71/71] {'loss': '0.0975'}\n",
      "Epoch 4 [71/71] {'loss': '0.0263'}\n",
      "Epoch 5 [71/71] {'loss': '0.105'}}\n",
      "Epoch 6 [71/71] {'loss': '0.0547'}\n",
      "Epoch 7 [71/71] {'loss': '0.0128'}}\n",
      "Epoch 8 [71/71] {'loss': '0.00575'}\n",
      "Epoch 9 [71/71] {'loss': '0.0176'}}\n",
      "Epoch 10 [71/71] {'loss': '0.128'}}\n",
      "Epoch 11 [71/71] {'loss': '0.106'}\n",
      "Epoch 12 [71/71] {'loss': '0.115'}}\n",
      "Epoch 13 [71/71] {'loss': '0.357'}}\n",
      "Epoch 14 [71/71] {'loss': '0.242'}\n",
      "Epoch 15 [71/71] {'loss': '0.0699'}\n",
      "Epoch 16 [71/71] {'loss': '0.102'}}\n",
      "Epoch 17 [71/71] {'loss': '0.0161'}\n",
      "Epoch 18 [71/71] {'loss': '0.0215'}}\n",
      "Epoch 19 [71/71] {'loss': '0.00295'}\n",
      "Epoch 20 [71/71] {'loss': '0.00482'}}\n",
      "Epoch 21 [71/71] {'loss': '0.00422'}\n",
      "Epoch 22 [71/71] {'loss': '0.00154'}}\n",
      "Epoch 23 [71/71] {'loss': '0.000957'}\n",
      "Epoch 24 [71/71] {'loss': '0.00247'}}\n",
      "Epoch 25 [71/71] {'loss': '0.00187'}}\n",
      "Epoch 26 [71/71] {'loss': '0.000552'}\n",
      "Epoch 27 [71/71] {'loss': '0.000467'}\n",
      "Epoch 28 [71/71] {'loss': '0.000322'}\n",
      "Epoch 29 [71/71] {'loss': '0.000659'}\n",
      "Epoch 30 [71/71] {'loss': '0.000418'}\n",
      "Epoch 31 [71/71] {'loss': '0.000802'}\n",
      "Epoch 32 [71/71] {'loss': '0.00236'}}\n",
      "Epoch 33 [71/71] {'loss': '0.00873'}}\n",
      "Epoch 34 [71/71] {'loss': '0.439'}}\n",
      "Epoch 35 [71/71] {'loss': '0.364'}\n",
      "Epoch 36 [71/71] {'loss': '0.104'}}\n",
      "Epoch 37 [71/71] {'loss': '0.116'}}\n",
      "Epoch 38 [71/71] {'loss': '0.0795'}\n",
      "Epoch 39 [71/71] {'loss': '0.079'}}\n",
      "Epoch 40 [71/71] {'loss': '0.305'}}\n",
      "Epoch 41 [71/71] {'loss': '0.0668'}\n",
      "Epoch 42 [71/71] {'loss': '0.0252'}}\n",
      "Epoch 43 [71/71] {'loss': '0.00353'}\n",
      "Epoch 44 [71/71] {'loss': '0.00112'}\n",
      "Epoch 45 [71/71] {'loss': '0.00937'}\n",
      "Epoch 46 [71/71] {'loss': '0.00128'}}\n",
      "Epoch 47 [71/71] {'loss': '0.00134'}}\n",
      "Epoch 48 [71/71] {'loss': '0.000883'}\n",
      "Epoch 49 [71/71] {'loss': '0.000369'}\n",
      "Epoch 50 [71/71] {'loss': '0.00119'}}\n",
      "Epoch 51 [71/71] {'loss': '0.000688'}\n",
      "Epoch 52 [71/71] {'loss': '0.00048'}}\n",
      "Epoch 53 [71/71] {'loss': '0.000676'}\n",
      "Epoch 54 [71/71] {'loss': '0.000285'}\n",
      "Epoch 55 [71/71] {'loss': '0.000455'}\n",
      "Epoch 56 [71/71] {'loss': '0.000283'}\n",
      "Epoch 57 [71/71] {'loss': '0.000267'}\n",
      "Epoch 58 [71/71] {'loss': '0.000352'}\n",
      "Epoch 59 [71/71] {'loss': '0.000227'}\n",
      "Epoch 60 [71/71] {'loss': '0.00023'}}\n",
      "Epoch 61 [71/71] {'loss': '0.000339'}\n",
      "Epoch 62 [71/71] {'loss': '0.000725'}\n",
      "Epoch 63 [71/71] {'loss': '0.000197'}\n",
      "Epoch 64 [71/71] {'loss': '0.000162'}\n",
      "Epoch 65 [71/71] {'loss': '0.000166'}\n",
      "Epoch 66 [71/71] {'loss': '0.000102'}\n",
      "Epoch 67 [71/71] {'loss': '8.64e-05'}\n",
      "Epoch 68 [71/71] {'loss': '0.000701'}\n",
      "Epoch 69 [71/71] {'loss': '0.000269'}\n",
      "Epoch 70 [71/71] {'loss': '0.000124'}\n",
      "Epoch 71 [71/71] {'loss': '0.000197'}\n",
      "Epoch 72 [71/71] {'loss': '0.000193'}\n",
      "Epoch 73 [71/71] {'loss': '7.92e-05'}\n",
      "Epoch 74 [12/71] {'loss': '0.000116'}\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  4853.4         \t|  100 %          \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  65.465         \t|74             \t|  4844.4         \t|  99.815         \t|\n",
      "run_training_batch                 \t|  0.73843        \t|5196           \t|  3836.9         \t|  79.056         \t|\n",
      "optimizer_step_and_closure_0       \t|  0.73164        \t|5196           \t|  3801.6         \t|  78.329         \t|\n",
      "training_step_and_backward         \t|  0.15234        \t|5196           \t|  791.54         \t|  16.309         \t|\n",
      "model_backward                     \t|  0.12886        \t|5196           \t|  669.57         \t|  13.796         \t|\n",
      "on_validation_end                  \t|  6.496          \t|74             \t|  480.71         \t|  9.9045         \t|\n",
      "model_forward                      \t|  0.022927       \t|5196           \t|  119.13         \t|  2.4546         \t|\n",
      "training_step                      \t|  0.022732       \t|5196           \t|  118.11         \t|  2.4336         \t|\n",
      "evaluation_step_and_end            \t|  0.13951        \t|586            \t|  81.753         \t|  1.6845         \t|\n",
      "validation_step                    \t|  0.13938        \t|586            \t|  81.678         \t|  1.6829         \t|\n",
      "get_train_batch                    \t|  0.014965       \t|5196           \t|  77.758         \t|  1.6021         \t|\n",
      "on_validation_epoch_end            \t|  0.37377        \t|74             \t|  27.659         \t|  0.5699         \t|\n",
      "on_train_batch_end                 \t|  0.00099608     \t|5195           \t|  5.1746         \t|  0.10662        \t|\n",
      "on_train_end                       \t|  0.27309        \t|1              \t|  0.27309        \t|  0.0056268      \t|\n",
      "on_after_backward                  \t|  5.2541e-05     \t|5196           \t|  0.273          \t|  0.005625       \t|\n",
      "cache_result                       \t|  8.3883e-06     \t|28550          \t|  0.23949        \t|  0.0049344      \t|\n",
      "on_batch_start                     \t|  3.7046e-05     \t|5196           \t|  0.19249        \t|  0.0039661      \t|\n",
      "on_before_zero_grad                \t|  2.9514e-05     \t|5195           \t|  0.15333        \t|  0.0031591      \t|\n",
      "on_epoch_start                     \t|  0.0015145      \t|74             \t|  0.11207        \t|  0.0023091      \t|\n",
      "on_train_batch_start               \t|  1.7502e-05     \t|5196           \t|  0.090941       \t|  0.0018738      \t|\n",
      "on_batch_end                       \t|  1.6431e-05     \t|5195           \t|  0.085361       \t|  0.0017588      \t|\n",
      "on_validation_batch_end            \t|  0.00010063     \t|586            \t|  0.05897        \t|  0.001215       \t|\n",
      "training_step_end                  \t|  9.6985e-06     \t|5196           \t|  0.050393       \t|  0.0010383      \t|\n",
      "on_train_epoch_end                 \t|  0.00059622     \t|73             \t|  0.043524       \t|  0.00089678     \t|\n",
      "on_validation_batch_start          \t|  3.4045e-05     \t|586            \t|  0.01995        \t|  0.00041106     \t|\n",
      "on_train_start                     \t|  0.0079606      \t|1              \t|  0.0079606      \t|  0.00016402     \t|\n",
      "validation_step_end                \t|  1.0791e-05     \t|586            \t|  0.0063237      \t|  0.00013029     \t|\n",
      "on_epoch_end                       \t|  2.6017e-05     \t|147            \t|  0.0038244      \t|  7.8799e-05     \t|\n",
      "on_validation_start                \t|  2.5803e-05     \t|74             \t|  0.0019094      \t|  3.9342e-05     \t|\n",
      "on_train_epoch_start               \t|  1.7655e-05     \t|74             \t|  0.0013065      \t|  2.6919e-05     \t|\n",
      "on_validation_epoch_start          \t|  1.4064e-05     \t|74             \t|  0.0010408      \t|  2.1444e-05     \t|\n",
      "on_fit_start                       \t|  1.8161e-05     \t|1              \t|  1.8161e-05     \t|  3.7419e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  7.0608e-06     \t|1              \t|  7.0608e-06     \t|  1.4548e-07     \t|\n",
      "\n",
      "INFO:lightning:\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  4853.4         \t|  100 %          \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  65.465         \t|74             \t|  4844.4         \t|  99.815         \t|\n",
      "run_training_batch                 \t|  0.73843        \t|5196           \t|  3836.9         \t|  79.056         \t|\n",
      "optimizer_step_and_closure_0       \t|  0.73164        \t|5196           \t|  3801.6         \t|  78.329         \t|\n",
      "training_step_and_backward         \t|  0.15234        \t|5196           \t|  791.54         \t|  16.309         \t|\n",
      "model_backward                     \t|  0.12886        \t|5196           \t|  669.57         \t|  13.796         \t|\n",
      "on_validation_end                  \t|  6.496          \t|74             \t|  480.71         \t|  9.9045         \t|\n",
      "model_forward                      \t|  0.022927       \t|5196           \t|  119.13         \t|  2.4546         \t|\n",
      "training_step                      \t|  0.022732       \t|5196           \t|  118.11         \t|  2.4336         \t|\n",
      "evaluation_step_and_end            \t|  0.13951        \t|586            \t|  81.753         \t|  1.6845         \t|\n",
      "validation_step                    \t|  0.13938        \t|586            \t|  81.678         \t|  1.6829         \t|\n",
      "get_train_batch                    \t|  0.014965       \t|5196           \t|  77.758         \t|  1.6021         \t|\n",
      "on_validation_epoch_end            \t|  0.37377        \t|74             \t|  27.659         \t|  0.5699         \t|\n",
      "on_train_batch_end                 \t|  0.00099608     \t|5195           \t|  5.1746         \t|  0.10662        \t|\n",
      "on_train_end                       \t|  0.27309        \t|1              \t|  0.27309        \t|  0.0056268      \t|\n",
      "on_after_backward                  \t|  5.2541e-05     \t|5196           \t|  0.273          \t|  0.005625       \t|\n",
      "cache_result                       \t|  8.3883e-06     \t|28550          \t|  0.23949        \t|  0.0049344      \t|\n",
      "on_batch_start                     \t|  3.7046e-05     \t|5196           \t|  0.19249        \t|  0.0039661      \t|\n",
      "on_before_zero_grad                \t|  2.9514e-05     \t|5195           \t|  0.15333        \t|  0.0031591      \t|\n",
      "on_epoch_start                     \t|  0.0015145      \t|74             \t|  0.11207        \t|  0.0023091      \t|\n",
      "on_train_batch_start               \t|  1.7502e-05     \t|5196           \t|  0.090941       \t|  0.0018738      \t|\n",
      "on_batch_end                       \t|  1.6431e-05     \t|5195           \t|  0.085361       \t|  0.0017588      \t|\n",
      "on_validation_batch_end            \t|  0.00010063     \t|586            \t|  0.05897        \t|  0.001215       \t|\n",
      "training_step_end                  \t|  9.6985e-06     \t|5196           \t|  0.050393       \t|  0.0010383      \t|\n",
      "on_train_epoch_end                 \t|  0.00059622     \t|73             \t|  0.043524       \t|  0.00089678     \t|\n",
      "on_validation_batch_start          \t|  3.4045e-05     \t|586            \t|  0.01995        \t|  0.00041106     \t|\n",
      "on_train_start                     \t|  0.0079606      \t|1              \t|  0.0079606      \t|  0.00016402     \t|\n",
      "validation_step_end                \t|  1.0791e-05     \t|586            \t|  0.0063237      \t|  0.00013029     \t|\n",
      "on_epoch_end                       \t|  2.6017e-05     \t|147            \t|  0.0038244      \t|  7.8799e-05     \t|\n",
      "on_validation_start                \t|  2.5803e-05     \t|74             \t|  0.0019094      \t|  3.9342e-05     \t|\n",
      "on_train_epoch_start               \t|  1.7655e-05     \t|74             \t|  0.0013065      \t|  2.6919e-05     \t|\n",
      "on_validation_epoch_start          \t|  1.4064e-05     \t|74             \t|  0.0010408      \t|  2.1444e-05     \t|\n",
      "on_fit_start                       \t|  1.8161e-05     \t|1              \t|  1.8161e-05     \t|  3.7419e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  7.0608e-06     \t|1              \t|  7.0608e-06     \t|  1.4548e-07     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-third",
   "metadata": {},
   "source": [
    "# Setup Input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weekly-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-blame",
   "metadata": {},
   "source": [
    "# Example model to plot CAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.cam import get_cam\n",
    "from neural_network.utils.cam_plots import plot_CAM_grid\n",
    "from neural_network.utils import move_to_device, to_cpu_numpy\n",
    "from neural_network.utils import interactive_slices, interactive_slices_masked\n",
    "def cam_example(agent, extractor_name:str='SmoothGradCAMpp',img_size:tuple=(79,224,224), plot_type:str='grid',cmap:str='jet', alpha:float=0.3, observed_class:str=None, load_image:str='CN'):\n",
    "    #label = 0\n",
    "    target_layer = 'model.layer4'\n",
    "    model = type(agent.model.model).__name__\n",
    "    \n",
    "    image = {\n",
    "        'CN':nib.load('data/SPM_categorised/AIH/CN/CN_ADNI_998.nii').get_fdata,\n",
    "        'MCI':nib.load('data/SPM_categorised/AIH/MCI/MCI_ADNI_1586.nii').get_fdata,\n",
    "        'AD':nib.load('data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii').get_fdata\n",
    "    }[load_image]()\n",
    "    label_to_class = {\n",
    "        0:'CN',\n",
    "        1:'MCI',\n",
    "        2:'AD'\n",
    "    }\n",
    "    class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "    \n",
    "    image = torch.from_numpy(resize(image, img_size)).float()\n",
    "    model = agent.model\n",
    "\n",
    "    model, image = move_to_device(model, image, 'cuda')\n",
    "    \n",
    "    mask, predicted_label = get_cam(model, image, extractor_name=extractor_name, target_layer=target_layer, observed_class=class_to_label[observed_class])\n",
    "    \n",
    "    #print(\"Number of slices above threshold:\", sum(mask > 150))\n",
    "    \n",
    "    \n",
    "    observed_class = observed_class if observed_class else load_image\n",
    "    \n",
    "    if plot_type == 'grid':\n",
    "        fig = plot_CAM_grid(to_cpu_numpy(image), mask,layer=target_layer, label=label_to_class[predicted_label], observed_class=observed_class,extractor=extractor_name,cmap=cmap, alpha=alpha)\n",
    "        \n",
    "    elif plot_type == 'slice':\n",
    "        testplot = interactive_slices()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image))\n",
    "        #testplot.cycle(0.1)\n",
    "        testplot.close()\n",
    "    elif plot_type == 'slice_masked':\n",
    "        testplot = interactive_slices_masked()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image), mask)\n",
    "        #testplot.cycle(1)\n",
    "        \n",
    "        testplot.close()\n",
    "    return (fig,mask, predicted_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sonic-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n"
     ]
    }
   ],
   "source": [
    "# Iterate all cams\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter(log_dir=f'logs/visualisation/version_{round(time.time())}', filename_suffix='.CAM')\n",
    "\n",
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD']\n",
    "errors = []\n",
    "\n",
    "for extractor_name, params in plot_cams.items():\n",
    "    for image in images:\n",
    "        for observed_class in observed_classes:\n",
    "            try:\n",
    "                fig,_,_ = cam_example(agent,extractor_name=extractor_name, **params,load_image=image,observed_class=observed_class)\n",
    "                tb_writer.add_figure(f\"{extractor_name}/{image}/{observed_class}\",fig)\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                errors.append((f'Model: {extractor_name} {e}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distant-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "favorite-potter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.06413430e-03, 3.18989344e-03, 2.24037934e-03, 4.07983243e-05,\n",
       "         1.64672697e-03, 3.40794376e-03, 3.04511283e-03],\n",
       "        [2.05302909e-02, 8.99572521e-02, 1.09509155e-01, 9.21289399e-02,\n",
       "         9.66381952e-02, 4.49617058e-02, 3.85731272e-02],\n",
       "        [3.77208740e-02, 2.85771847e-01, 3.13196659e-01, 1.88670173e-01,\n",
       "         1.72440961e-01, 5.05159199e-02, 3.75668444e-02],\n",
       "        [5.57416864e-02, 3.88459951e-01, 4.27888453e-01, 2.09720522e-01,\n",
       "         1.27726614e-01, 6.14761077e-02, 4.40539792e-02],\n",
       "        [5.13880998e-02, 3.73264939e-01, 3.93005818e-01, 1.86727062e-01,\n",
       "         8.91030133e-02, 7.03534037e-02, 3.61692198e-02],\n",
       "        [3.57444398e-02, 2.23318651e-01, 2.03232110e-01, 9.55260918e-02,\n",
       "         7.71973133e-02, 7.11510852e-02, 3.74832042e-02],\n",
       "        [1.34040527e-02, 6.65361062e-02, 4.81477119e-02, 1.41306072e-02,\n",
       "         2.75531486e-02, 2.22721286e-02, 3.03215720e-02]],\n",
       "\n",
       "       [[3.56701110e-03, 8.15110689e-04, 0.00000000e+00, 2.49054725e-03,\n",
       "         2.32837107e-02, 1.23406006e-02, 4.41026175e-03],\n",
       "        [1.20284431e-01, 3.15957487e-01, 2.22325385e-01, 3.32752377e-01,\n",
       "         4.03663665e-01, 1.21250115e-01, 7.58220926e-02],\n",
       "        [2.33133495e-01, 7.63353288e-01, 6.16061747e-01, 8.02464426e-01,\n",
       "         4.76324052e-01, 1.27111465e-01, 1.26399532e-01],\n",
       "        [2.27694124e-01, 1.00000000e+00, 9.11221087e-01, 8.62548113e-01,\n",
       "         2.63157666e-01, 1.48573652e-01, 1.11838952e-01],\n",
       "        [2.21006021e-01, 9.91949201e-01, 8.80040050e-01, 7.07584381e-01,\n",
       "         1.25671580e-01, 1.43633693e-01, 9.42917913e-02],\n",
       "        [2.23732293e-01, 6.86969697e-01, 4.76268113e-01, 2.82929182e-01,\n",
       "         1.54005840e-01, 1.56787232e-01, 4.47059982e-02],\n",
       "        [1.13307081e-01, 1.68656021e-01, 5.12167253e-02, 4.36911508e-02,\n",
       "         5.27210198e-02, 2.44754478e-02, 3.68530415e-02]],\n",
       "\n",
       "       [[7.48979393e-03, 1.12931477e-02, 7.12819537e-03, 2.05118544e-02,\n",
       "         3.68609875e-02, 2.61729062e-02, 2.52857758e-03],\n",
       "        [1.09467566e-01, 4.25246000e-01, 3.73701930e-01, 3.20850492e-01,\n",
       "         3.26470196e-01, 1.74041480e-01, 5.89088947e-02],\n",
       "        [1.81553081e-01, 7.78523862e-01, 7.04661369e-01, 6.52927339e-01,\n",
       "         2.78010637e-01, 1.47299230e-01, 8.35607871e-02],\n",
       "        [1.97762370e-01, 9.56893384e-01, 9.29333568e-01, 6.17752433e-01,\n",
       "         1.79994226e-01, 1.18428975e-01, 7.51789734e-02],\n",
       "        [1.84001043e-01, 9.97721553e-01, 8.60045612e-01, 4.73571658e-01,\n",
       "         1.51387483e-01, 1.23283193e-01, 5.53367995e-02],\n",
       "        [1.64760500e-01, 7.39954412e-01, 4.64968801e-01, 2.32407585e-01,\n",
       "         1.42630503e-01, 7.74086788e-02, 2.33345702e-02],\n",
       "        [8.89536068e-02, 2.70732135e-01, 6.99762553e-02, 9.68055651e-02,\n",
       "         2.66150441e-02, 1.34768328e-02, 9.49819945e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD']\n",
    "fig,mask,_ = cam_example(agent,extractor_name='SmoothGradCAMpp', **params,load_image='AD',observed_class='CN')\n",
    "mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fancy-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask*255 > 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "measured-gibson",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-04a8e556619b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np_mask' is not defined"
     ]
    }
   ],
   "source": [
    "sum(np_mask[0]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask = to_np_figure(mask).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "retri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask[to_np_figure(mask)>150].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np_fig_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import to_np_figure, to_np_fig_grid\n",
    "\n",
    "len(sum(numpy_to_image_grid(mask)>160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((fig*255).astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "cam_example(agent,extractor_name='GradCAM', plot_type='slice_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-intelligence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.imshow((first_image[0].squeeze(0)[50] * 255).numpy().astype(np.uint8), cmap='gray')\n",
    "plt.imshow((darp[50] * 255).astype(np.uint8), cmap='jet', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import interactive_slices\n",
    "testplot = interactive_slices()\n",
    "testplot.multi_slice_viewer(darp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.cam.cam import SmoothGradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = SmoothGradCAMpp(model,target_layer=model.model.layer4[1].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cam, idx = wrapped_model(first_image[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
