{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floral-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serious-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affecting-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from neural_network.trainer import Agent\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bridal-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup configurations...\n",
      "Dataset sizes - Training: 421 Validation: 47 Test: 0\n",
      "Loading architecture from logs/tb_logs/lightning/resnet50/version_2/checkpoints/epoch=34-step=2424.ckpt (checkpoint)..\n",
      "Model [LightningModel] was created\n",
      "logs/tb_logs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "agent = Agent('resnet50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trained-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-celebration",
   "metadata": {},
   "source": [
    "# Setup Input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tutorial-utilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading architecture from logs/tb_logs/lightning/resnet50/version_2/checkpoints/epoch=34-step=2424.ckpt (checkpoint)..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model [LightningModel] was created\n",
      "logs/tb_logs/\n"
     ]
    }
   ],
   "source": [
    "agent.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-norwegian",
   "metadata": {},
   "source": [
    "# Example model to plot CAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appointed-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.cam import get_cam\n",
    "from neural_network.utils.cam_plots import plot_CAM_grid\n",
    "from neural_network.utils import move_to_device, to_cpu_numpy\n",
    "from neural_network.utils import interactive_slices, interactive_slices_masked\n",
    "def cam_example(agent, extractor_name:str='SmoothGradCAMpp',img_size:tuple=(79,224,224), plot_type:str='grid',cmap:str='jet', alpha:float=0.3, observed_class:str=None, load_image:str='CN'):\n",
    "    #label = 0\n",
    "    target_layer = 'model.layer4'\n",
    "    model = type(agent.model.model).__name__\n",
    "    \n",
    "    image = {\n",
    "        'CN':nib.load('data/SPM_categorised/AIH/CN/CN_ADNI_998.nii').get_fdata,\n",
    "        'MCI':nib.load('data/SPM_categorised/AIH/MCI/MCI_ADNI_1586.nii').get_fdata,\n",
    "        'AD':nib.load('data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii').get_fdata\n",
    "    }[load_image]()\n",
    "    label_to_class = {\n",
    "        0:'CN',\n",
    "        1:'MCI',\n",
    "        2:'AD'\n",
    "    }\n",
    "    class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "    \n",
    "    image = torch.from_numpy(resize(image, img_size)).float()\n",
    "    model = agent.model\n",
    "\n",
    "    model, image = move_to_device(model, image, 'cuda')\n",
    "    \n",
    "    mask, predicted_label = get_cam(model, image, extractor_name=extractor_name, target_layer=target_layer, observed_class=class_to_label[observed_class])\n",
    "    \n",
    "    #print(\"Number of slices above threshold:\", sum(mask > 150))\n",
    "    \n",
    "    predicted_override=True if observed_class else False\n",
    "    \n",
    "    if plot_type == 'grid':\n",
    "        fig = plot_CAM_grid(to_cpu_numpy(image), mask,layer=target_layer, predicted_label=label_to_class[predicted_label], expected_label=load_image,extractor=extractor_name,cmap=cmap, alpha=alpha, predicted_override=predicted_override)\n",
    "        \n",
    "    elif plot_type == 'slice':\n",
    "        testplot = interactive_slices()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image))\n",
    "        #testplot.cycle(0.1)\n",
    "        testplot.close()\n",
    "    elif plot_type == 'slice_masked':\n",
    "        testplot = interactive_slices_masked()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image), mask)\n",
    "        #testplot.cycle(1)\n",
    "        \n",
    "        testplot.close()\n",
    "    return (fig,mask, predicted_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lined-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n",
      "WARNING:root:no value was provided for `fc_layer`, thus set to 'model.fc'.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e002e83244cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobserved_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobserved_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextractor_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextractor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserved_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{extractor_name}/{image}/{observed_class}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f0c02efa139e>\u001b[0m in \u001b[0;36mcam_example\u001b[0;34m(agent, extractor_name, img_size, plot_type, cmap, alpha, observed_class, load_image)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextractor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobserved_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print(\"Number of slices above threshold:\", sum(mask > 150))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "# Iterate all cams\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter(log_dir=f'logs/visualisation/version_{round(time.time())}', filename_suffix='.CAM')\n",
    "\n",
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD',None]\n",
    "errors = []\n",
    "\n",
    "for extractor_name, params in plot_cams.items():\n",
    "    for image in images:\n",
    "        for observed_class in observed_classes:\n",
    "            try:\n",
    "                fig,_,_ = cam_example(agent,extractor_name=extractor_name, **params,load_image=image,observed_class=observed_class)\n",
    "                tb_writer.add_figure(f\"{extractor_name}/{image}/{observed_class}\",fig)\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                errors.append((f'Model: {extractor_name} {e}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD']\n",
    "fig,mask,_ = cam_example(agent,extractor_name='SmoothGradCAMpp', **params,load_image='AD',observed_class='CN')\n",
    "mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask*255 > 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np_mask[0]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask = to_np_figure(mask).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "retri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask[to_np_figure(mask)>150].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np_fig_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import to_np_figure, to_np_fig_grid\n",
    "\n",
    "len(sum(numpy_to_image_grid(mask)>160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((fig*255).astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "cam_example(agent,extractor_name='GradCAM', plot_type='slice_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-transportation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.imshow((first_image[0].squeeze(0)[50] * 255).numpy().astype(np.uint8), cmap='gray')\n",
    "plt.imshow((darp[50] * 255).astype(np.uint8), cmap='jet', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import interactive_slices\n",
    "testplot = interactive_slices()\n",
    "testplot.multi_slice_viewer(darp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.cam.cam import SmoothGradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = SmoothGradCAMpp(model,target_layer=model.model.layer4[1].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cam, idx = wrapped_model(first_image[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-boost",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
