{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "missing-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "checked-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vertical-movement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Training: 421 Validation: 47 Test: 0\n",
      "Architecture [VGG] was created\n",
      "Defined hyperparameters:, \n",
      " \"architecture_name\":   vgg16\n",
      "\"checkpoint_path\":     None\n",
      "\"class_weights\":       None\n",
      "\"hp_metrics\":          ['loss/val', 'loss/train', 'accuracy/val', 'auc/val', 'specificity/val', 'sensitivity/val']\n",
      "\"is_train\":            True\n",
      "\"loss_weight_balance\": True\n",
      "\"lr\":                  0.0002\n",
      "\"lr_decay_iters\":      10\n",
      "\"lr_policy\":           step\n",
      "\"max_epochs\":          200\n",
      "\"model_name\":          lightning\n",
      "\"opt_amsgrad\":         False\n",
      "\"opt_weight_decay\":    1e-05\n",
      "Model [LightningModel] was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "%autoreload \n",
    "from neural_network.trainer import load_trainer\n",
    "trainer, dataset, model = load_trainer('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-lender",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VGG  | 163 M \n",
      "-------------------------------\n",
      "163 M     Trainable params\n",
      "0         Non-trainable params\n",
      "163 M     Total params\n",
      "654.761   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 [47/71] {'loss': '1.1'}\r"
     ]
    }
   ],
   "source": [
    "%autoreload \n",
    "trainer.fit(\n",
    "    model, \n",
    "    datamodule=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-architecture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-madison",
   "metadata": {},
   "source": [
    "# Example model to plot CAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.cam import get_cam\n",
    "from neural_network.utils.cam_plots import plot_CAM_grid\n",
    "from neural_network.utils import move_to_device, to_cpu_numpy\n",
    "from neural_network.utils import interactive_slices, interactive_slices_masked\n",
    "def cam_example(agent, extractor_name:str='SmoothGradCAMpp',img_size:tuple=(79,224,224), plot_type:str='grid',cmap:str='jet', alpha:float=0.3, observed_class:str=None, load_image:str='CN'):\n",
    "    #label = 0\n",
    "    target_layer = 'model.layer4'\n",
    "    model = type(agent.model.model).__name__\n",
    "    \n",
    "    image = {\n",
    "        'CN':nib.load('data/SPM_categorised/AIH/CN/CN_ADNI_998.nii').get_fdata,\n",
    "        'MCI':nib.load('data/SPM_categorised/AIH/MCI/MCI_ADNI_1586.nii').get_fdata,\n",
    "        'AD':nib.load('data/SPM_categorised/AIH/AD/AD_ADNI_2975.nii').get_fdata\n",
    "    }[load_image]()\n",
    "    label_to_class = {\n",
    "        0:'CN',\n",
    "        1:'MCI',\n",
    "        2:'AD'\n",
    "    }\n",
    "    class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "    \n",
    "    image = torch.from_numpy(resize(image, img_size)).float()\n",
    "    model = agent.model\n",
    "\n",
    "    model, image = move_to_device(model, image, 'cuda')\n",
    "    \n",
    "    mask, predicted_label = get_cam(model, image, extractor_name=extractor_name, target_layer=target_layer, observed_class=class_to_label[observed_class])\n",
    "    \n",
    "    #print(\"Number of slices above threshold:\", sum(mask > 150))\n",
    "    \n",
    "    predicted_override=True if observed_class else False\n",
    "    \n",
    "    if plot_type == 'grid':\n",
    "        fig = plot_CAM_grid(to_cpu_numpy(image), mask,layer=target_layer, predicted_label=label_to_class[predicted_label], expected_label=load_image,extractor=extractor_name,cmap=cmap, alpha=alpha, predicted_override=predicted_override)\n",
    "        \n",
    "    elif plot_type == 'slice':\n",
    "        testplot = interactive_slices()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image))\n",
    "        #testplot.cycle(0.1)\n",
    "        testplot.close()\n",
    "    elif plot_type == 'slice_masked':\n",
    "        testplot = interactive_slices_masked()\n",
    "        testplot.multi_slice_viewer(to_cpu_numpy(image), mask)\n",
    "        #testplot.cycle(1)\n",
    "        \n",
    "        testplot.close()\n",
    "    return (fig,mask, predicted_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate all cams\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter(log_dir=f'logs/visualisation/version_{round(time.time())}', filename_suffix='.CAM')\n",
    "\n",
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD',None]\n",
    "errors = []\n",
    "\n",
    "for extractor_name, params in plot_cams.items():\n",
    "    for image in images:\n",
    "        for observed_class in observed_classes:\n",
    "            try:\n",
    "                fig,_,_ = cam_example(agent,extractor_name=extractor_name, **params,load_image=image,observed_class=observed_class)\n",
    "                tb_writer.add_figure(f\"{extractor_name}/{image}/{observed_class}\",fig)\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                errors.append((f'Model: {extractor_name} {e}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cams = {\n",
    "    'CAM':{},\n",
    "    'GradCAM':{},\n",
    "    'GradCAMpp':{},\n",
    "    'SmoothGradCAMpp':{},\n",
    "    'Saliency':{'cmap':'hot', 'alpha':1},\n",
    "    'ScoreCAM':{},\n",
    "    'SSCAM':{},\n",
    "    'ISCAM':{},\n",
    "}\n",
    "images = ['CN','MCI','AD']#[:1]\n",
    "observed_classes = ['CN','MCI','AD']\n",
    "fig,mask,_ = cam_example(agent,extractor_name='SmoothGradCAMpp', **params,load_image='AD',observed_class='CN')\n",
    "mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask*255 > 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np_mask[0]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask = to_np_figure(mask).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "retri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mask[to_np_figure(mask)>150].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np_fig_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import to_np_figure, to_np_fig_grid\n",
    "\n",
    "len(sum(numpy_to_image_grid(mask)>160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((fig*255).astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "cam_example(agent,extractor_name='GradCAM', plot_type='slice_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.imshow((first_image[0].squeeze(0)[50] * 255).numpy().astype(np.uint8), cmap='gray')\n",
    "plt.imshow((darp[50] * 255).astype(np.uint8), cmap='jet', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.utils.utils import interactive_slices\n",
    "testplot = interactive_slices()\n",
    "testplot.multi_slice_viewer(darp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.cam.cam import SmoothGradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = SmoothGradCAMpp(model,target_layer=model.model.layer4[1].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cam, idx = wrapped_model(first_image[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
