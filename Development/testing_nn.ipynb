{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funny-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from neural_network.cam.cams import SmoothGradCAMpp, SSCAM, ScoreCAM\n",
    "from neural_network.trainer import Agent\n",
    "from neural_network.utils.utils import interactive_slices,interactive_slices_masked\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "planned-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup configurations...\n",
      "Dataset sizes - Training: 421 Validation: 47 Test: 0\n",
      "architecture [ResNet] was created\n",
      "model [LightningModel] was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent('resnet50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "speaking-treaty",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 46.2 M\n",
      "---------------------------------\n",
      "46.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "46.2 M    Total params\n",
      "184.645   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 [71/71] {'loss': '1.16'}\n",
      "Epoch 2 [71/71] {'loss': '1.14'}\n",
      "Epoch 3 [71/71] {'loss': '1.07'}}\n",
      "Epoch 4 [71/71] {'loss': '1.21'}}\n",
      "Epoch 5 [71/71] {'loss': '1.02'}}\n",
      "Epoch 6 [71/71] {'loss': '0.973'}\n",
      "Epoch 7 [71/71] {'loss': '0.856'}\n",
      "Epoch 8 [71/71] {'loss': '0.826'}\n",
      "Epoch 9 [71/71] {'loss': '0.837'}\n",
      "Epoch 10 [71/71] {'loss': '0.792'}\n",
      "Epoch 11 [71/71] {'loss': '0.803'}\n",
      "Epoch 12 [71/71] {'loss': '0.648'}\n",
      "Epoch 13 [71/71] {'loss': '0.861'}\n",
      "Epoch 14 [71/71] {'loss': '0.687'}\n",
      "Epoch 15 [71/71] {'loss': '0.792'}\n",
      "Epoch 16 [71/71] {'loss': '0.577'}\n",
      "Epoch 17 [71/71] {'loss': '0.579'}\n",
      "Epoch 18 [71/71] {'loss': '0.632'}\n",
      "Epoch 19 [71/71] {'loss': '0.602'}\n",
      "Epoch 20 [71/71] {'loss': '0.572'}\n",
      "Epoch 21 [71/71] {'loss': '0.543'}\n",
      "Epoch 22 [71/71] {'loss': '0.537'}\n",
      "Epoch 23 [71/71] {'loss': '0.622'}\n",
      "Epoch 24 [71/71] {'loss': '0.519'}\n",
      "Epoch 25 [71/71] {'loss': '0.263'}\n",
      "Epoch 26 [71/71] {'loss': '0.223'}\n",
      "Epoch 27 [71/71] {'loss': '0.262'}\n",
      "Epoch 28 [71/71] {'loss': '0.304'}\n",
      "Epoch 29 [71/71] {'loss': '0.304'}\n",
      "Epoch 30 [71/71] {'loss': '0.0816'}\n",
      "Epoch 31 [71/71] {'loss': '0.0218'}\n",
      "Epoch 32 [71/71] {'loss': '0.0789'}\n",
      "Epoch 33 [71/71] {'loss': '0.0982'}\n",
      "Epoch 34 [71/71] {'loss': '0.0305'}\n",
      "Epoch 35 [71/71] {'loss': '0.0166'}\n",
      "Epoch 36 [71/71] {'loss': '0.063'}}}\n",
      "Epoch 37 [71/71] {'loss': '0.0986'}\n",
      "Epoch 38 [71/71] {'loss': '0.13'}}}\n",
      "Epoch 39 [71/71] {'loss': '0.103'}}\n",
      "Epoch 40 [71/71] {'loss': '0.143'}}\n",
      "Epoch 41 [71/71] {'loss': '0.178'}\n",
      "Epoch 42 [71/71] {'loss': '0.0695'}\n",
      "Epoch 43 [71/71] {'loss': '0.0196'}\n",
      "Epoch 44 [71/71] {'loss': '0.00326'}\n",
      "Epoch 45 [71/71] {'loss': '0.00197'}\n",
      "Epoch 46 [71/71] {'loss': '0.0479'}}}\n",
      "Epoch 47 [71/71] {'loss': '0.275'}\n",
      "Epoch 48 [71/71] {'loss': '0.285'}}\n",
      "Epoch 49 [71/71] {'loss': '0.0619'}\n",
      "Epoch 50 [71/71] {'loss': '0.0567'}\n",
      "Epoch 51 [71/71] {'loss': '0.0573'}\n",
      "Epoch 52 [71/71] {'loss': '0.00925'}\n",
      "Epoch 53 [71/71] {'loss': '0.00956'}\n",
      "Epoch 54 [71/71] {'loss': '0.0029'}}\n",
      "Epoch 55 [71/71] {'loss': '0.00428'}}\n",
      "Epoch 56 [71/71] {'loss': '0.00142'}}\n",
      "Epoch 57 [19/71] {'loss': '0.00265'}\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/stud/f/fremar16/miniconda3/envs/Master-thesis/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3077.7         \t|  100 %          \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  53.965         \t|57             \t|  3076.0         \t|  99.945         \t|\n",
      "run_training_batch                 \t|  0.72074        \t|3996           \t|  2880.1         \t|  93.58          \t|\n",
      "optimizer_step_and_closure_0       \t|  0.71674        \t|3996           \t|  2864.1         \t|  93.061         \t|\n",
      "training_step_and_backward         \t|  0.16322        \t|3996           \t|  652.24         \t|  21.193         \t|\n",
      "model_backward                     \t|  0.13869        \t|3996           \t|  554.21         \t|  18.007         \t|\n",
      "model_forward                      \t|  0.024148       \t|3996           \t|  96.495         \t|  3.1353         \t|\n",
      "training_step                      \t|  0.023942       \t|3996           \t|  95.674         \t|  3.1086         \t|\n",
      "evaluation_step_and_end            \t|  0.14009        \t|450            \t|  63.04          \t|  2.0483         \t|\n",
      "validation_step                    \t|  0.13996        \t|450            \t|  62.98          \t|  2.0464         \t|\n",
      "get_train_batch                    \t|  0.014473       \t|3996           \t|  57.833         \t|  1.8791         \t|\n",
      "on_validation_epoch_end            \t|  0.23854        \t|57             \t|  13.597         \t|  0.44178        \t|\n",
      "on_train_batch_end                 \t|  0.0009808      \t|3995           \t|  3.9183         \t|  0.12731        \t|\n",
      "on_train_end                       \t|  0.23015        \t|1              \t|  0.23015        \t|  0.007478       \t|\n",
      "cache_result                       \t|  7.2914e-06     \t|21955          \t|  0.16008        \t|  0.0052015      \t|\n",
      "on_batch_start                     \t|  3.5392e-05     \t|3996           \t|  0.14143        \t|  0.0045953      \t|\n",
      "on_before_zero_grad                \t|  2.8243e-05     \t|3995           \t|  0.11283        \t|  0.0036661      \t|\n",
      "on_after_backward                  \t|  2.7874e-05     \t|3996           \t|  0.11138        \t|  0.0036191      \t|\n",
      "on_epoch_start                     \t|  0.0013574      \t|57             \t|  0.077369       \t|  0.0025139      \t|\n",
      "on_train_batch_start               \t|  1.8276e-05     \t|3996           \t|  0.073032       \t|  0.002373       \t|\n",
      "on_batch_end                       \t|  1.6739e-05     \t|3995           \t|  0.066874       \t|  0.0021729      \t|\n",
      "on_validation_batch_end            \t|  0.00010426     \t|450            \t|  0.046916       \t|  0.0015244      \t|\n",
      "training_step_end                  \t|  1.035e-05      \t|3996           \t|  0.041359       \t|  0.0013439      \t|\n",
      "on_train_epoch_end                 \t|  0.00049107     \t|56             \t|  0.0275         \t|  0.00089354     \t|\n",
      "on_validation_batch_start          \t|  3.5027e-05     \t|450            \t|  0.015762       \t|  0.00051215     \t|\n",
      "validation_step_end                \t|  1.0497e-05     \t|450            \t|  0.0047237      \t|  0.00015348     \t|\n",
      "on_train_start                     \t|  0.0041845      \t|1              \t|  0.0041845      \t|  0.00013596     \t|\n",
      "on_epoch_end                       \t|  2.3387e-05     \t|113            \t|  0.0026428      \t|  8.5869e-05     \t|\n",
      "on_validation_end                  \t|  3.8907e-05     \t|57             \t|  0.0022177      \t|  7.2058e-05     \t|\n",
      "on_validation_start                \t|  2.2613e-05     \t|57             \t|  0.001289       \t|  4.1881e-05     \t|\n",
      "on_train_epoch_start               \t|  2.1421e-05     \t|57             \t|  0.001221       \t|  3.9672e-05     \t|\n",
      "on_validation_epoch_start          \t|  1.4521e-05     \t|57             \t|  0.00082769     \t|  2.6894e-05     \t|\n",
      "on_fit_start                       \t|  4.7494e-05     \t|1              \t|  4.7494e-05     \t|  1.5432e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  6.3786e-06     \t|1              \t|  6.3786e-06     \t|  2.0726e-07     \t|\n",
      "\n",
      "INFO:lightning:\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3077.7         \t|  100 %          \t|\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  53.965         \t|57             \t|  3076.0         \t|  99.945         \t|\n",
      "run_training_batch                 \t|  0.72074        \t|3996           \t|  2880.1         \t|  93.58          \t|\n",
      "optimizer_step_and_closure_0       \t|  0.71674        \t|3996           \t|  2864.1         \t|  93.061         \t|\n",
      "training_step_and_backward         \t|  0.16322        \t|3996           \t|  652.24         \t|  21.193         \t|\n",
      "model_backward                     \t|  0.13869        \t|3996           \t|  554.21         \t|  18.007         \t|\n",
      "model_forward                      \t|  0.024148       \t|3996           \t|  96.495         \t|  3.1353         \t|\n",
      "training_step                      \t|  0.023942       \t|3996           \t|  95.674         \t|  3.1086         \t|\n",
      "evaluation_step_and_end            \t|  0.14009        \t|450            \t|  63.04          \t|  2.0483         \t|\n",
      "validation_step                    \t|  0.13996        \t|450            \t|  62.98          \t|  2.0464         \t|\n",
      "get_train_batch                    \t|  0.014473       \t|3996           \t|  57.833         \t|  1.8791         \t|\n",
      "on_validation_epoch_end            \t|  0.23854        \t|57             \t|  13.597         \t|  0.44178        \t|\n",
      "on_train_batch_end                 \t|  0.0009808      \t|3995           \t|  3.9183         \t|  0.12731        \t|\n",
      "on_train_end                       \t|  0.23015        \t|1              \t|  0.23015        \t|  0.007478       \t|\n",
      "cache_result                       \t|  7.2914e-06     \t|21955          \t|  0.16008        \t|  0.0052015      \t|\n",
      "on_batch_start                     \t|  3.5392e-05     \t|3996           \t|  0.14143        \t|  0.0045953      \t|\n",
      "on_before_zero_grad                \t|  2.8243e-05     \t|3995           \t|  0.11283        \t|  0.0036661      \t|\n",
      "on_after_backward                  \t|  2.7874e-05     \t|3996           \t|  0.11138        \t|  0.0036191      \t|\n",
      "on_epoch_start                     \t|  0.0013574      \t|57             \t|  0.077369       \t|  0.0025139      \t|\n",
      "on_train_batch_start               \t|  1.8276e-05     \t|3996           \t|  0.073032       \t|  0.002373       \t|\n",
      "on_batch_end                       \t|  1.6739e-05     \t|3995           \t|  0.066874       \t|  0.0021729      \t|\n",
      "on_validation_batch_end            \t|  0.00010426     \t|450            \t|  0.046916       \t|  0.0015244      \t|\n",
      "training_step_end                  \t|  1.035e-05      \t|3996           \t|  0.041359       \t|  0.0013439      \t|\n",
      "on_train_epoch_end                 \t|  0.00049107     \t|56             \t|  0.0275         \t|  0.00089354     \t|\n",
      "on_validation_batch_start          \t|  3.5027e-05     \t|450            \t|  0.015762       \t|  0.00051215     \t|\n",
      "validation_step_end                \t|  1.0497e-05     \t|450            \t|  0.0047237      \t|  0.00015348     \t|\n",
      "on_train_start                     \t|  0.0041845      \t|1              \t|  0.0041845      \t|  0.00013596     \t|\n",
      "on_epoch_end                       \t|  2.3387e-05     \t|113            \t|  0.0026428      \t|  8.5869e-05     \t|\n",
      "on_validation_end                  \t|  3.8907e-05     \t|57             \t|  0.0022177      \t|  7.2058e-05     \t|\n",
      "on_validation_start                \t|  2.2613e-05     \t|57             \t|  0.001289       \t|  4.1881e-05     \t|\n",
      "on_train_epoch_start               \t|  2.1421e-05     \t|57             \t|  0.001221       \t|  3.9672e-05     \t|\n",
      "on_validation_epoch_start          \t|  1.4521e-05     \t|57             \t|  0.00082769     \t|  2.6894e-05     \t|\n",
      "on_fit_start                       \t|  4.7494e-05     \t|1              \t|  4.7494e-05     \t|  1.5432e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  6.3786e-06     \t|1              \t|  6.3786e-06     \t|  2.0726e-07     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "australian-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = iter(agent.dataset.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_label = next(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import M3d-CAM\n",
    "from medcam import medcam\n",
    "\n",
    "# Init your model and dataloader\n",
    "model = agent.model\n",
    "data_loader = agent.dataset.val_dataloader()\n",
    "\n",
    "# Inject model with M3d-CAM\n",
    "model = medcam.inject(model, backend='gcampp',output_dir=\"attention_maps\", label=0,layer='model.layer4',save_maps=True,data_shape=(79,224,224))\n",
    "\n",
    "model.eval()\n",
    "output = model(first_image[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "grand-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "darp = medcam.medcam_utils.normalize(model.medcam_dict['current_attention_map'])\n",
    "darp = resize(darp.squeeze(0).squeeze(0),(79,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "moved-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "incomplete-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96880959887e4cc1959541c5e5be00d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "plt.close()\n",
    "#for first_image, first_label in agent.dataset.val_dataloader():\n",
    "\n",
    "output = model(first_image[0].unsqueeze(0))\n",
    "\n",
    "asd = interactive_slices_masked()\n",
    "asd.multi_slice_viewer(first_image[0],darp)\n",
    "#asd.cycle(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "regulated-slovakia",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e5e2c5df2f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/stud1/f/fremar16/Master_thesis/Development/neural_network/utils/utils.py\u001b[0m in \u001b[0;36mcycle\u001b[0;34m(self, timer)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sustainable-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c74b91998c44d6490cce5ff9a8c02cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.imshow((first_image[0].squeeze(0)[50] * 255).numpy().astype(np.uint8), cmap='gray')\n",
    "plt.imshow((darp[50] * 255).astype(np.uint8), cmap='jet', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "superior-polls",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02801a7f4aa34b4ab2653c64b344dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neural_network.utils.utils import interactive_slices\n",
    "testplot = interactive_slices()\n",
    "testplot.multi_slice_viewer(darp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "agricultural-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network.cam.cam import SmoothGradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "structural-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = SmoothGradCAMpp(model,target_layer=model.model.layer4[1].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "artistic-carol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 79, 224, 224])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "specific-drive",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5c7e085e5343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/stud1/f/fremar16/Master_thesis/Development/neural_network/cam/cam.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/stud1/f/fremar16/Master_thesis/Development/neural_network/cam/cam.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, idx)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Master-thesis/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cam, idx = wrapped_model(first_image[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-danish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "master-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
